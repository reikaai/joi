---
phase: 01-codebase-alignment-audit
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - .planning/phases/01-codebase-alignment-audit/AUDIT.md
autonomous: true
requirements:
  - AUDIT-01
  - AUDIT-02
  - AUDIT-03

must_haves:
  truths:
    - "Every subsystem (graph, tools, memory, tasks, media delegate, context management, sandbox, client/telegram) has an aligned/neutral/misaligned verdict for each of the 4 strategic goals"
    - "Each misalignment cell has a written rationale explaining WHY it's misaligned, not just that it is"
    - "A prioritized fix list exists, ranked by weighted impact score across all 4 goals"
    - "The tasks subsystem's position in the fix list validates or challenges experimenting on it first"
  artifacts:
    - path: ".planning/phases/01-codebase-alignment-audit/AUDIT.md"
      provides: "Complete codebase alignment audit"
      contains: "Alignment Matrix"
    - path: ".planning/phases/01-codebase-alignment-audit/AUDIT.md"
      provides: "Prioritized fix list"
      contains: "Prioritized Fix List"
  key_links:
    - from: "AUDIT.md alignment matrix"
      to: "AUDIT.md fix list"
      via: "Misaligned cells feed into fix list items"
      pattern: "misaligned.*fix"
---

<objective>
Produce the complete codebase alignment audit: an 8x4 scorecard evaluating each Joi subsystem against the 4 strategic goals, misalignment reasoning, a prioritized fix list, and a validation of the tasks-first experiment decision.

Purpose: Establish evidence-based understanding of which subsystems serve the strategic goals and which need rework, informing all future milestone planning.
Output: `.planning/phases/01-codebase-alignment-audit/AUDIT.md`
</objective>

<execution_context>
@/Users/iorlas/.claude/get-shit-done/workflows/execute-plan.md
@/Users/iorlas/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/codebase/ARCHITECTURE.md
@.planning/codebase/CONCERNS.md
@.planning/codebase/STRUCTURE.md
@.planning/codebase/STACK.md
@.planning/codebase/INTEGRATIONS.md
@.planning/codebase/CONVENTIONS.md
@.planning/codebase/TESTING.md
@docs/strategic-context.md
@.planning/phases/01-codebase-alignment-audit/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build alignment matrix with per-cell verdicts and misalignment reasoning</name>
  <files>.planning/phases/01-codebase-alignment-audit/AUDIT.md</files>
  <action>
Read all 7 codebase docs from `.planning/codebase/` and `docs/strategic-context.md`. Also read the actual source files for each subsystem to validate the preliminary findings from the research:

- `src/joi_agent_langgraph2/graph.py` (Graph Core)
- `src/joi_agent_langgraph2/tools.py` (Tool Loading)
- `src/joi_mcp/` directory (MCP servers)
- `src/joi_agent_langgraph2/memory.py` (Memory)
- `src/joi_agent_langgraph2/tasks/` directory (Tasks)
- `src/joi_agent_langgraph2/delegates.py` (Media Delegate)
- `src/joi_agent_langgraph2/interpreter.py` (Sandbox)
- `src/joi_langgraph_client/` directory (Client)
- `src/joi_telegram_langgraph/` directory (Telegram)

For context management, look at middleware sections in `graph.py`.

Create `.planning/phases/01-codebase-alignment-audit/AUDIT.md` with these sections:

**Section 1: Alignment Matrix** — A markdown table with 8 rows (subsystems) and 4 columns (goals). Each cell contains a verdict (Aligned/Neutral/Misaligned) and a one-sentence rationale. Use the research's subsystem definitions and goal operationalization criteria. Do NOT copy the research's preliminary findings verbatim — verify against actual source code and adjust if findings differ.

**Section 2: Misalignment Details** — For every cell marked "Misaligned" in the matrix, write a paragraph explaining:
- WHAT is misaligned (specific evidence from code/docs)
- WHY it matters for this goal (connect to the goal's evaluation criteria)
- DIRECTION to fix (not detailed design — just "needs X" level)

Avoid pitfalls from research:
- Don't conflate code quality with strategic alignment
- Don't scope-creep into design recommendations
- Don't use binary keep/rewrite thinking
- Don't under-weight the "daily tool" goal

The evaluation scale is:
- **Aligned**: Subsystem serves this goal well in its current state
- **Neutral**: Subsystem doesn't strongly serve or hurt this goal
- **Misaligned**: Subsystem actively works against this goal or has critical gaps
  </action>
  <verify>
AUDIT.md exists and contains:
1. An "Alignment Matrix" section with a table containing 8 subsystem rows and 4 goal columns
2. Each cell has a verdict (Aligned/Neutral/Misaligned) plus rationale
3. A "Misalignment Details" section with a paragraph for every Misaligned cell
4. Each misalignment paragraph has WHAT/WHY/DIRECTION structure
  </verify>
  <done>All 32 matrix cells filled with evidence-based verdicts and rationales. Every misalignment has written reasoning with specific evidence from code or docs.</done>
</task>

<task type="auto">
  <name>Task 2: Produce prioritized fix list and validate tasks-first decision</name>
  <files>.planning/phases/01-codebase-alignment-audit/AUDIT.md</files>
  <action>
Add two sections to the existing AUDIT.md:

**Section 3: Prioritized Fix List** — Derive from the misalignment details. For each distinct misalignment issue (group by subsystem + root cause, not by cell):
- Subsystem name
- Issue description (one sentence)
- Impact score: weighted sum of goals affected. Weights: Manifesto=3, Skills=3, Breakaway=2, Daily=2. Score = sum of weights for each goal where this issue causes a "Misaligned" verdict. Range: 0-10.
- Effort bucket: S (hours), M (days), L (weeks)
- Sort descending by impact score

Format as a markdown table.

**Section 4: Tasks Subsystem Validation** — Dedicated section answering: "Is tasks the right first experiment target?" Structure:
- Where tasks ranks in the fix list (position and score)
- Evidence FOR experimenting on tasks first (from the audit findings, not just the research)
- Evidence AGAINST (other subsystems that might benefit more)
- Verdict: confirm or challenge the tasks-first decision, with reasoning

Keep the entire audit proportional — this is a sanity check. The full document should be 200-400 lines, not a dissertation.
  </action>
  <verify>
AUDIT.md contains:
1. A "Prioritized Fix List" section with a sorted table (impact score descending)
2. Each fix item has: subsystem, issue, impact score (0-10), effort (S/M/L)
3. A "Tasks Subsystem Validation" section with evidence for/against and a clear verdict
4. Total document is under 500 lines
  </verify>
  <done>Fix list is ranked by impact. Tasks subsystem position validates or challenges the experiment-first decision with specific evidence. Document is proportional to sanity-check scope.</done>
</task>

</tasks>

<verification>
1. AUDIT.md contains all 4 sections: Alignment Matrix, Misalignment Details, Prioritized Fix List, Tasks Subsystem Validation
2. All 8 subsystems evaluated against all 4 goals (32 cells)
3. Every "Misaligned" cell has corresponding reasoning in the details section
4. Fix list is sorted by impact score with no items missing from misalignment details
5. Tasks validation section gives a clear yes/no with evidence
</verification>

<success_criteria>
- The alignment matrix reveals which subsystems need attention and which are fine
- The fix list can directly inform future GSD milestones
- The tasks validation provides evidence-based confirmation (or rejection) of the experiment-first decision
- A reader unfamiliar with the codebase can understand each verdict from the rationale alone
</success_criteria>

<output>
After completion, create `.planning/phases/01-codebase-alignment-audit/01-01-SUMMARY.md`
</output>
